{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4dc7d0-fb8a-4191-92ef-72d443fc2f2f",
   "metadata": {},
   "source": [
    "## Daily Monte Carlo Block Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac188f8-1c18-4dfa-bed7-bfef13811135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Fetching JTO/USDT 1d OHLCV from Binance (last 1000 bars)...\n",
      "[i] Spot: 1.661000\n",
      "[i] Running block-bootstrap Monte Carlo: paths=10,000, horizon_bars=60, block_len=24\n",
      "\n",
      "[i] บันทึกผลลัพธ์ลงไฟล์ CSV แล้ว: macro_montecarlo.csv\n",
      "\n",
      "=== ผลลัพธ์ Macro Monte Carlo (1D, ใช้ประวัติ 1000 แท่ง) ===\n",
      " ราคาปัจจุบัน (Spot): 1.661000\n",
      " ความน่าจะเป็น 'ลงไปแตะ' ต่ำกว่า 1.54: 85.43%\n",
      " ความน่าจะเป็น 'ขึ้นไปแตะ' สูงกว่า 4.10: 1.09%\n",
      " ค่าต่ำสุดในช่วงจำลอง (เปอร์เซ็นไทล์ p10/p50/p90): [0.896699, 1.270727, 1.593093]\n",
      " ค่าสูงสุดในช่วงจำลอง (เปอร์เซ็นไทล์ p10/p50/p90): [1.699793, 2.091319, 2.927268]\n",
      "\n",
      "[แถบคาดการณ์จากเปอร์เซ็นไทล์]  p10_min ไป p90_max\n",
      " ช่วงราคา: 0.896699 ไป 2.927268  (ความกว้าง 2.030569)\n",
      "\n",
      "[ข้อเสนอการวางกริด]\n",
      " ระยะห่างขั้น (step) = $0.10 | จำนวนชั้นสูงสุด = 12\n",
      " ชั้นฝั่งลง (6): [1.061, 1.161, 1.261, 1.361, 1.461, 1.561]\n",
      " ชั้นฝั่งขึ้น (6): [1.761, 1.861, 1.961, 2.061, 2.161, 2.261]\n",
      "\n",
      "เสร็จสิ้นเมื่อ (GMT+7): 2025-09-22 08:45:31 UTC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Macro Monte Carlo for XRP/USDT (1D x 1000 bars) — no argparse version\n",
    "- ดึง OHLCV 1D ย้อนหลัง 1000 แท่งจาก Binance ด้วย ccxt\n",
    "- คำนวณ log-returns จากราคาปิด (ไม่ใช้ TA)\n",
    "- Block-bootstrap Monte Carlo (คงโครงสร้างในบล็อก)\n",
    "- สรุปความน่าจะเป็นแตะกรอบ $2 / $4, percentile ของ min/max ในอนาคต\n",
    "- แนะนำกริดจากแถบเปอร์เซ็นไทล์ (บังคับ step $0.10 และจำกัดจำนวนชั้น)\n",
    "\n",
    "ติดตั้ง: pip install ccxt pandas numpy\n",
    "\"\"\"\n",
    "\n",
    "import ccxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "CONFIG = {\n",
    "    \"symbol\": \"JTO/USDT\",\n",
    "    \"timeframe\": \"1d\",\n",
    "    \"lookback_bars\": 1000,     # ใช้แท่งล่าสุด 1000 แท่ง\n",
    "    \"paths\": 10000,            # จำนวนเส้นทาง MC\n",
    "    \"horizon_bars\": 60,        # ระยะมองไปข้างหน้า (วัน)\n",
    "    \"block_len\": 24,           # ความยาวบล็อกสำหรับ bootstrap\n",
    "    \"band_percentiles\": (10, 90),  # ใช้ p10 ของ minimum และ p90 ของ maximum\n",
    "    \"lower_level\": 1.54,       # กรอบ Macro ด้านล่างที่อยากประเมิน P(touch)\n",
    "    \"upper_level\": 4.10,       # กรอบ Macro ด้านบนที่อยากประเมิน P(touch)\n",
    "    \"grid_min_step\": 0.10,     # บังคับระยะห่างไมโคร $0.10\n",
    "    \"max_layers\": 12,          # จำกัดจำนวนชั้นกริดรวม (ขึ้น+ลง)\n",
    "    \"seed\": 42                 # เพื่อความ reproducible; ตั้งเป็น None ถ้าไม่ต้องการ\n",
    "}\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "def fetch_ohlcv_1d_binance(symbol: str, lookback_bars: int) -> pd.DataFrame:\n",
    "    ex = ccxt.binance({\"enableRateLimit\": True})\n",
    "    # ดึงล่าสุด 1000 แท่งตรง ๆ\n",
    "    raw = ex.fetch_ohlcv(symbol, timeframe=\"1d\", limit=lookback_bars)\n",
    "    if not raw or len(raw) < 50:\n",
    "        raise RuntimeError(\"Not enough OHLCV returned.\")\n",
    "    df = pd.DataFrame(raw, columns=[\"ts\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "    df[\"dt\"] = pd.to_datetime(df[\"ts\"], unit=\"ms\", utc=True).dt.tz_convert(\"Asia/Bangkok\")\n",
    "    return df[[\"dt\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "\n",
    "def block_bootstrap_returns(ret: np.ndarray, horizon: int, block_len: int, paths: int, rng: np.random.Generator):\n",
    "    \"\"\"\n",
    "    สุ่มบล็อกของ log-returns จากอดีตมาต่อ ๆ กันจนได้ความยาวตาม horizon\n",
    "    ret: 1D numpy array ของ log-returns ประวัติ\n",
    "    return: ndarray shape = (paths, horizon) ของ simulated log-returns\n",
    "    \"\"\"\n",
    "    n = len(ret)\n",
    "    if n < block_len + 5:\n",
    "        raise ValueError(\"Return history too short for chosen block_len.\")\n",
    "    out = np.empty((paths, horizon), dtype=float)\n",
    "\n",
    "    # indices ที่เริ่มบล็อกได้ (ให้มีที่ว่าง block_len)\n",
    "    valid_starts = np.arange(0, n - block_len + 1)\n",
    "\n",
    "    for p in range(paths):\n",
    "        path = []\n",
    "        while len(path) < horizon:\n",
    "            start = rng.choice(valid_starts)\n",
    "            blk = ret[start:start + block_len]\n",
    "            path.extend(blk.tolist())\n",
    "        out[p, :] = np.array(path[:horizon])\n",
    "    return out\n",
    "\n",
    "\n",
    "def simulate_price_paths(spot: float, logret_paths: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    แปลง log-returns → เส้นทางราคา (geometric compounding จาก spot)\n",
    "    logret_paths: (paths, horizon)\n",
    "    return prices: (paths, horizon)\n",
    "    \"\"\"\n",
    "    cum = np.cumsum(logret_paths, axis=1)\n",
    "    prices = spot * np.exp(cum)\n",
    "    return prices\n",
    "\n",
    "\n",
    "def prob_touch_level(paths: np.ndarray, level: float, side: str) -> float:\n",
    "    \"\"\"\n",
    "    side='down' → เคยลงต่ำกว่า level ไหม\n",
    "    side='up'   → เคยขึ้นสูงกว่า level ไหม\n",
    "    \"\"\"\n",
    "    if side == \"down\":\n",
    "        touched = (paths.min(axis=1) <= level)\n",
    "    else:\n",
    "        touched = (paths.max(axis=1) >= level)\n",
    "    return float(touched.mean()) * 100.0\n",
    "\n",
    "\n",
    "def summarize_macro(prices: np.ndarray, spot: float, lower: float, upper: float, p_lo=10, p_hi=90):\n",
    "    \"\"\"\n",
    "    สรุป percentiles ของ min/max ในช่วงอนาคต และ P(touch) ระดับสำคัญ\n",
    "    \"\"\"\n",
    "    path_min = prices.min(axis=1)\n",
    "    path_max = prices.max(axis=1)\n",
    "\n",
    "    p_touch_low = prob_touch_level(prices, lower, \"down\")\n",
    "    p_touch_high = prob_touch_level(prices, upper, \"up\")\n",
    "\n",
    "    # percentiles\n",
    "    pct = [10, 50, 90]\n",
    "    min_pct = np.percentile(path_min, pct).tolist()\n",
    "    max_pct = np.percentile(path_max, pct).tolist()\n",
    "\n",
    "    band_low = np.percentile(path_min, p_lo)\n",
    "    band_high = np.percentile(path_max, p_hi)\n",
    "\n",
    "    return {\n",
    "        \"spot\": spot,\n",
    "        \"p_touch_low\": p_touch_low,\n",
    "        \"p_touch_high\": p_touch_high,\n",
    "        \"min_pct\": min_pct,\n",
    "        \"max_pct\": max_pct,\n",
    "        \"band_low\": float(band_low),\n",
    "        \"band_high\": float(band_high)\n",
    "    }\n",
    "\n",
    "\n",
    "def suggest_grid(spot: float, band_low: float, band_high: float, step: float, max_layers: int):\n",
    "    \"\"\"\n",
    "    สร้างแผนกริดคร่าว ๆ จาก band (p10_min → p90_max) ด้วย step บังคับ\n",
    "    - จำกัดจำนวนชั้นรวม (ขึ้น+ลง) ตาม max_layers\n",
    "    \"\"\"\n",
    "    # เลเยอร์ฝั่งลง\n",
    "    dn_levels = []\n",
    "    price = spot - step\n",
    "    while price >= band_low + 1e-9:\n",
    "        dn_levels.append(round(price, 4))\n",
    "        price -= step\n",
    "\n",
    "    # เลเยอร์ฝั่งขึ้น\n",
    "    up_levels = []\n",
    "    price = spot + step\n",
    "    while price <= band_high - 1e-9:\n",
    "        up_levels.append(round(price, 4))\n",
    "        price += step\n",
    "\n",
    "    # จำกัดจำนวนชั้นรวม\n",
    "    total = len(dn_levels) + len(up_levels)\n",
    "    if total > max_layers:\n",
    "        # ตัดแบบสัดส่วน (ให้ล่างมากกว่านิด ๆ ก็ได้)\n",
    "        # ที่ง่ายสุด: ตัดปลายทั้งสองจนเหลือรวม = max_layers โดยสลับตัด\n",
    "        keep_dn = len(dn_levels)\n",
    "        keep_up = len(up_levels)\n",
    "        while (keep_dn + keep_up) > max_layers:\n",
    "            if keep_dn >= keep_up and keep_dn > 0:\n",
    "                keep_dn -= 1\n",
    "            elif keep_up > 0:\n",
    "                keep_up -= 1\n",
    "            else:\n",
    "                break\n",
    "        dn_levels = dn_levels[:keep_dn]\n",
    "        up_levels = up_levels[:keep_up]\n",
    "\n",
    "    return dn_levels[::-1], up_levels  # เรียงล่าง→ใกล้ spot ก่อนสำหรับฝั่งลง\n",
    "\n",
    "\n",
    "def export_macro_csv(csv_filename: str, cfg: dict, summ: dict, path_min: np.ndarray, path_max: np.ndarray):\n",
    "    \"\"\"\n",
    "    เขียน CSV แบบรวม:\n",
    "      1) ส่วน path-level: path_id, min_price, max_price\n",
    "         (คอลัมน์สรุปทั้งหมดจะเป็น NaN)\n",
    "      2) ต่อด้วยส่วนสรุป 1 แถว: spot, p_touch_low, p_touch_high, band_low, band_high,\n",
    "         min_p10/min_p50/min_p90, max_p10/max_p50/max_p90 และ metadata พื้นฐาน\n",
    "\n",
    "    ไฟล์เดียว อ่านง่ายต่อ pipeline ที่คาด schema เดิม\n",
    "    \"\"\"\n",
    "    # --- 1) Path-level ---\n",
    "    paths_df = pd.DataFrame({\n",
    "        \"path_id\": np.arange(len(path_min), dtype=int),\n",
    "        \"min_price\": path_min.astype(float),\n",
    "        \"max_price\": path_max.astype(float),\n",
    "    })\n",
    "\n",
    "    # เติมคอลัมน์สรุป (เป็น NaN สำหรับส่วน path)\n",
    "    summary_cols = {\n",
    "        \"spot\": np.nan,\n",
    "        \"p_touch_low\": np.nan,\n",
    "        \"p_touch_high\": np.nan,\n",
    "        \"band_low\": np.nan,\n",
    "        \"band_high\": np.nan,\n",
    "        \"min_p10\": np.nan, \"min_p50\": np.nan, \"min_p90\": np.nan,\n",
    "        \"max_p10\": np.nan, \"max_p50\": np.nan, \"max_p90\": np.nan,\n",
    "        # optional metadata\n",
    "        \"symbol\": None,\n",
    "        \"timeframe\": None,\n",
    "        \"lookback_bars\": np.nan,\n",
    "        \"paths\": np.nan,\n",
    "        \"horizon_bars\": np.nan,\n",
    "        \"block_len\": np.nan,\n",
    "        \"band_lo_pct\": np.nan,\n",
    "        \"band_hi_pct\": np.nan,\n",
    "        \"lower_level\": np.nan,\n",
    "        \"upper_level\": np.nan,\n",
    "        \"generated_at_gmt7\": None,\n",
    "    }\n",
    "    for k in summary_cols:\n",
    "        paths_df[k] = summary_cols[k]\n",
    "\n",
    "    # --- 2) Summary 1 row ---\n",
    "    summ_df = pd.DataFrame([{\n",
    "        \"path_id\": np.nan,\n",
    "        \"min_price\": np.nan,\n",
    "        \"max_price\": np.nan,\n",
    "        \"spot\": float(summ[\"spot\"]),\n",
    "        \"p_touch_low\": float(summ[\"p_touch_low\"]),\n",
    "        \"p_touch_high\": float(summ[\"p_touch_high\"]),\n",
    "        \"band_low\": float(summ[\"band_low\"]),\n",
    "        \"band_high\": float(summ[\"band_high\"]),\n",
    "        \"min_p10\": float(summ[\"min_pct\"][0]),\n",
    "        \"min_p50\": float(summ[\"min_pct\"][1]),\n",
    "        \"min_p90\": float(summ[\"min_pct\"][2]),\n",
    "        \"max_p10\": float(summ[\"max_pct\"][0]),\n",
    "        \"max_p50\": float(summ[\"max_pct\"][1]),\n",
    "        \"max_p90\": float(summ[\"max_pct\"][2]),\n",
    "        # metadata (ช่วยให้ reproducible/debug ได้)\n",
    "        \"symbol\": cfg[\"symbol\"],\n",
    "        \"timeframe\": cfg[\"timeframe\"],\n",
    "        \"lookback_bars\": int(cfg[\"lookback_bars\"]),\n",
    "        \"paths\": int(cfg[\"paths\"]),\n",
    "        \"horizon_bars\": int(cfg[\"horizon_bars\"]),\n",
    "        \"block_len\": int(cfg[\"block_len\"]),\n",
    "        \"band_lo_pct\": int(cfg[\"band_percentiles\"][0]),\n",
    "        \"band_hi_pct\": int(cfg[\"band_percentiles\"][1]),\n",
    "        \"lower_level\": float(cfg[\"lower_level\"]),\n",
    "        \"upper_level\": float(cfg[\"upper_level\"]),\n",
    "        \"generated_at_gmt7\": datetime.now(timezone.utc).astimezone().strftime('%Y-%m-%d %H:%M:%S %Z'),\n",
    "    }])\n",
    "\n",
    "    out_all = pd.concat([paths_df, summ_df], ignore_index=True)\n",
    "    out_all.to_csv(csv_filename, index=False)\n",
    "def export_macro_csv(csv_filename: str, cfg: dict, summ: dict, path_min: np.ndarray, path_max: np.ndarray):\n",
    "    \"\"\"\n",
    "    เขียน CSV แบบรวม:\n",
    "      1) ส่วน path-level: path_id, min_price, max_price\n",
    "         (คอลัมน์สรุปทั้งหมดจะเป็น NaN)\n",
    "      2) ต่อด้วยส่วนสรุป 1 แถว: spot, p_touch_low, p_touch_high, band_low, band_high,\n",
    "         min_p10/min_p50/min_p90, max_p10/max_p50/max_p90 และ metadata พื้นฐาน\n",
    "\n",
    "    ไฟล์เดียว อ่านง่ายต่อ pipeline ที่คาด schema เดิม\n",
    "    \"\"\"\n",
    "    # --- 1) Path-level ---\n",
    "    paths_df = pd.DataFrame({\n",
    "        \"path_id\": np.arange(len(path_min), dtype=int),\n",
    "        \"min_price\": path_min.astype(float),\n",
    "        \"max_price\": path_max.astype(float),\n",
    "    })\n",
    "\n",
    "    # เติมคอลัมน์สรุป (เป็น NaN สำหรับส่วน path)\n",
    "    summary_cols = {\n",
    "        \"spot\": np.nan,\n",
    "        \"p_touch_low\": np.nan,\n",
    "        \"p_touch_high\": np.nan,\n",
    "        \"band_low\": np.nan,\n",
    "        \"band_high\": np.nan,\n",
    "        \"min_p10\": np.nan, \"min_p50\": np.nan, \"min_p90\": np.nan,\n",
    "        \"max_p10\": np.nan, \"max_p50\": np.nan, \"max_p90\": np.nan,\n",
    "        # optional metadata\n",
    "        \"symbol\": None,\n",
    "        \"timeframe\": None,\n",
    "        \"lookback_bars\": np.nan,\n",
    "        \"paths\": np.nan,\n",
    "        \"horizon_bars\": np.nan,\n",
    "        \"block_len\": np.nan,\n",
    "        \"band_lo_pct\": np.nan,\n",
    "        \"band_hi_pct\": np.nan,\n",
    "        \"lower_level\": np.nan,\n",
    "        \"upper_level\": np.nan,\n",
    "        \"generated_at_gmt7\": None,\n",
    "    }\n",
    "    for k in summary_cols:\n",
    "        paths_df[k] = summary_cols[k]\n",
    "\n",
    "    # --- 2) Summary 1 row ---\n",
    "    summ_df = pd.DataFrame([{\n",
    "        \"path_id\": np.nan,\n",
    "        \"min_price\": np.nan,\n",
    "        \"max_price\": np.nan,\n",
    "        \"spot\": float(summ[\"spot\"]),\n",
    "        \"p_touch_low\": float(summ[\"p_touch_low\"]),\n",
    "        \"p_touch_high\": float(summ[\"p_touch_high\"]),\n",
    "        \"band_low\": float(summ[\"band_low\"]),\n",
    "        \"band_high\": float(summ[\"band_high\"]),\n",
    "        \"min_p10\": float(summ[\"min_pct\"][0]),\n",
    "        \"min_p50\": float(summ[\"min_pct\"][1]),\n",
    "        \"min_p90\": float(summ[\"min_pct\"][2]),\n",
    "        \"max_p10\": float(summ[\"max_pct\"][0]),\n",
    "        \"max_p50\": float(summ[\"max_pct\"][1]),\n",
    "        \"max_p90\": float(summ[\"max_pct\"][2]),\n",
    "        # metadata (ช่วยให้ reproducible/debug ได้)\n",
    "        \"symbol\": cfg[\"symbol\"],\n",
    "        \"timeframe\": cfg[\"timeframe\"],\n",
    "        \"lookback_bars\": int(cfg[\"lookback_bars\"]),\n",
    "        \"paths\": int(cfg[\"paths\"]),\n",
    "        \"horizon_bars\": int(cfg[\"horizon_bars\"]),\n",
    "        \"block_len\": int(cfg[\"block_len\"]),\n",
    "        \"band_lo_pct\": int(cfg[\"band_percentiles\"][0]),\n",
    "        \"band_hi_pct\": int(cfg[\"band_percentiles\"][1]),\n",
    "        \"lower_level\": float(cfg[\"lower_level\"]),\n",
    "        \"upper_level\": float(cfg[\"upper_level\"]),\n",
    "        \"generated_at_gmt7\": datetime.now(timezone.utc).astimezone().strftime('%Y-%m-%d %H:%M:%S %Z'),\n",
    "    }])\n",
    "\n",
    "    out_all = pd.concat([paths_df, summ_df], ignore_index=True)\n",
    "    out_all.to_csv(csv_filename, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    cfg = CONFIG.copy()\n",
    "    rng = np.random.default_rng(cfg[\"seed\"]) if cfg[\"seed\"] is not None else np.random.default_rng()\n",
    "\n",
    "    print(f\"[i] Fetching {cfg['symbol']} {cfg['timeframe']} OHLCV from Binance (last {cfg['lookback_bars']} bars)...\")\n",
    "    df = fetch_ohlcv_1d_binance(cfg[\"symbol\"], cfg[\"lookback_bars\"])\n",
    "    close = df[\"close\"].to_numpy(dtype=float)\n",
    "\n",
    "    spot = float(close[-1])\n",
    "    logret = np.diff(np.log(close))\n",
    "\n",
    "    print(f\"[i] Spot: {spot:.6f}\")\n",
    "    print(f\"[i] Running block-bootstrap Monte Carlo: paths={cfg['paths']:,}, horizon_bars={cfg['horizon_bars']}, block_len={cfg['block_len']}\")\n",
    "    \n",
    "    # สุ่มเส้นทาง log-returns แล้วแปลงเป็นราคา\n",
    "    log_paths = block_bootstrap_returns(\n",
    "        ret=logret,\n",
    "        horizon=cfg[\"horizon_bars\"],\n",
    "        block_len=cfg[\"block_len\"],\n",
    "        paths=cfg[\"paths\"],\n",
    "        rng=rng\n",
    "    )\n",
    "    price_paths = simulate_price_paths(spot, log_paths)\n",
    "\n",
    "    # สรุปผล Macro\n",
    "    summ = summarize_macro(\n",
    "        price_paths, spot,\n",
    "        lower=cfg[\"lower_level\"],\n",
    "        upper=cfg[\"upper_level\"],\n",
    "        p_lo=CONFIG[\"band_percentiles\"][0],\n",
    "        p_hi=CONFIG[\"band_percentiles\"][1]\n",
    "    )\n",
    "\n",
    "    band_low = summ[\"band_low\"]\n",
    "    band_high = summ[\"band_high\"]\n",
    "    width = band_high - band_low\n",
    "\n",
    "    # สร้างกริดจาก band ด้วย step บังคับ\n",
    "    dn_levels, up_levels = suggest_grid(\n",
    "        spot=spot,\n",
    "        band_low=band_low,\n",
    "        band_high=band_high,\n",
    "        step=cfg[\"grid_min_step\"],\n",
    "        max_layers=cfg[\"max_layers\"]\n",
    "    )\n",
    "\n",
    "    # === บันทึก CSV รวม path-level + summary ===\n",
    "    export_macro_csv(\n",
    "        csv_filename=\"macro_montecarlo.csv\",\n",
    "        cfg=cfg,\n",
    "        summ=summ,\n",
    "        path_min=price_paths.min(axis=1),\n",
    "        path_max=price_paths.max(axis=1),\n",
    "    )\n",
    "    print(f\"\\n[i] บันทึกผลลัพธ์ลงไฟล์ CSV แล้ว: macro_montecarlo.csv\")\n",
    "\n",
    "    # ========= แสดงผล =========\n",
    "    print(\"\\n=== ผลลัพธ์ Macro Monte Carlo (1D, ใช้ประวัติ 1000 แท่ง) ===\")\n",
    "    print(f\" ราคาปัจจุบัน (Spot): {summ['spot']:.6f}\")\n",
    "    print(f\" ความน่าจะเป็น 'ลงไปแตะ' ต่ำกว่า {cfg['lower_level']:.2f}: {summ['p_touch_low']:.2f}%\")\n",
    "    print(f\" ความน่าจะเป็น 'ขึ้นไปแตะ' สูงกว่า {cfg['upper_level']:.2f}: {summ['p_touch_high']:.2f}%\")\n",
    "    print(f\" ค่าต่ำสุดในช่วงจำลอง (เปอร์เซ็นไทล์ p10/p50/p90): {np.round(summ['min_pct'], 6).tolist()}\")\n",
    "    print(f\" ค่าสูงสุดในช่วงจำลอง (เปอร์เซ็นไทล์ p10/p50/p90): {np.round(summ['max_pct'], 6).tolist()}\")\n",
    "    \n",
    "    print(f\"\\n[แถบคาดการณ์จากเปอร์เซ็นไทล์]  p{CONFIG['band_percentiles'][0]}_min ไป p{CONFIG['band_percentiles'][1]}_max\")\n",
    "    print(f\" ช่วงราคา: {band_low:.6f} ไป {band_high:.6f}  (ความกว้าง {width:.6f})\")\n",
    "    \n",
    "    print(\"\\n[ข้อเสนอการวางกริด]\")\n",
    "    print(f\" ระยะห่างขั้น (step) = ${cfg['grid_min_step']:.2f} | จำนวนชั้นสูงสุด = {cfg['max_layers']}\")\n",
    "    print(f\" ชั้นฝั่งลง ({len(dn_levels)}): {dn_levels}\")\n",
    "    print(f\" ชั้นฝั่งขึ้น ({len(up_levels)}): {up_levels}\")\n",
    "    print(f\"\\nเสร็จสิ้นเมื่อ (GMT+7): {datetime.now(timezone.utc).astimezone().strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742eaab2-7f8d-4699-9e67-1118ba0bd148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
